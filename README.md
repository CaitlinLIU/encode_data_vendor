## Intro

The project requires writing a Python application that can dynamically load data from historical ZIP files or CSV files based on a specified date and continuously update a raw_data.csv file. It also has to support live production usage.

## Key Points of Analysis

There are some key points in the description of the project: 

1. `we assume that markets are opened on all weekdays`: that is, all weekdays are trading dats and will have data uploaded theoretically. 
2. `he usually publishes one daily file at around 8:00am ET the next day`: i.e., if the data date is on Friday, we will receive it on Saturday.
3. `the file for the 26th of June 2019 arriving on the 27th of June 2019 at 8:19am ET would be located in 20190626/1561637940000000000.csv`: the name of folder is the data date instead of input date.
4. `encoder.py which builds and continuously updates a point in time file raw_data.csv`: output is **raw_data.csv**
5. `“encoder.py --date 20190611” to append the data we received on the 11th of June 2019 around 8:00am ET to raw_data.csv`: retrieve the previous trading date data of the input data.
6. `an example of the output raw_data.csv:`: compared to raw datasets, the example of output data has to be insert one more column **time** which is the nanoseconds of the file downloaded.

## Train-of-Thought

Here's a basic outline of structuring such an application:

1. Parse the command-line argument to get the date.
2. Check if the format of <input_date> valid.
3. Obtain the <data_date> and determine if the <data_date> is in the past, present, or future
4. Check the existence of the data file:
    - if not exists (downloading can be delayed in real life), wait for some time and periodically check. Exit the script if run timeout.
    - if exists, continue step 5.
5. Check if the data file is historical csv or zip:
    - Load the historical ZIP files or CSV files for the <data_date>
6. Build/append the data into output file **raw_data.csv**


## Assumptions

There are some ambiguity in the project discription and we clarify some assumptions here: 

1. In step 3, if the <input_date> (such as 20190714) is a Sunday or Monday, that is, the previous date is not a weekday (trading day), should we exit the program or return the last weekday (trading day) before this date anyway?
    - Here I assume it will still retrieve the data of last weekday (trading day) as long as the <input_date> is valid.
2. In step 3, the sample data `20190711` folder is missing, so the program will skip this date as it was not a trading date.
3. In step 4, files downloaded can delay in production. So it will check if the correspinding file exists every 30 seconds. If the attampts are more than 240 times (2 hours), the program will regard it as timeout and exit.
4. In step 5, there is no illustration on how many csv files are stored under the date directory  and the number of csv files in the zip file.
    - Here I assume that there can be duplidated csv file under the date directory. Since in real life, the data team could have downloaded the data multiple times at different nanoseconds. If these happend, the program will take the latest file as the most accurate one.
    - Here I assume the zip file contains only one CSV file historically.
5. In step 5, there was no information on the nanoseconds, hence will use NaN to fill the first **time** column.
6. In step 6, what if a data date already exists in **raw_data.csv**? Should I remove the duplicates?
    - Here I assume it can happend in real life. If the data were duplicated based on ('time', 'date' 'unique_id'), duplications will be removed.
7. In step 6, what if some columns of new data haven't appeared in **raw_data.csv** before?
    - If there are new columns that haven't appeared before, it will keep all columns and fill NA value in the new columns for historical data


## File Illustrations

1. **encoder.py** is the required script. You can use the command line `python3 encoder.py --date 20190611`to run it
2. **test.py** is the test script using provided sample data. You can use the command line `python3 test.py`to run it
3. **raw_data.csv** is the sample output generated by running test.py.
4. In production, you can set up the cronjob with the linux job scheduler <crontab>: `00 8 * * 1-5 python3 encoder.py > encoder.log 2>&1 &`
    - the job will be triggered at 8am every morning on weekdays and the running log will be saved as well. Notice that you don't need to pass the date to the script because the date is the present date by default

